# PMVGD: A Progressive Multi-View Graph Distillation Paradigm for Health Event Prediction 

Official implementation of our paper:  
> **PMVGD: A Progressive Multi-View Graph Distillation Paradigm for Health Event Prediction**  
> *Information Fusion, 2026*  

---

## ðŸ”¥ Introduction  

To address the trade-off between noisy full-graph modeling and information loss in simplified graphs, we propose a **Progressive Multi-View Graph Distillation paradigm (PMVGD)** for health event prediction.  

Specifically, we construct multi-view graphs from EHR and adopt a progressive teacherâ€“student learning process to integrate complementary clinical signals.

1. **Phase 1: Teacher Encoder Pretraining**  
    Pretrain the teacher on the disease graph to learn robust clinical patterns.

2. **Phase 2: Multi-View Graph Collaborative Learning**  
   Train student encoders on procedure and medication graphs under teacher guidance.

3. **Phase 3: Adaptive Sequential Distillation**  
   Distill multi-view knowledge back into the teacher for refined prediction.

Altogether, PMVGD converts distillation from a static, one-shot compression into an iterative cycle of mutual refinement.  

---
## ðŸ“Š Training Pipeline  

<p align="center">
  <img src="assets/pipeline.png" width="100%">
</p>

---

## ðŸš€ How to Run (Phase 1)

You can pretrain the **teacher encoder** on MIMIC-III using: 
```bash
python -m experiments.run_phase1 \
  --dataset mimic3 \
  --model teacher \
  --epoch_main 130 \
  --mimic3_path "PATH/TO/mimic3/hosp"
```
You can pretrain the **teacher encoder** on MIMIC-IV using: 
```bash
python -m experiments.run_phase1 \
  --dataset mimic4 \
  --model teacher \
  --epoch_main 70 \
  --mimic3_path "PATH/TO/mimic4/hosp"
```

> *Default checkpoints will be saved in `./ckpt/phase1/`.*  

---

## ðŸ“‚ Repository Structure  

```
PMVGD/
â”‚â”€â”€ trainers/
â”‚    â”œâ”€â”€ phase1_pretrain.py       # Phase 1 trainer
â”‚    â”œâ”€â”€ phase2_collab.py         # (coming soon)
â”‚    â””â”€â”€ phase3_distill.py        # (coming soon)
â”‚
â”‚â”€â”€ experiments/
â”‚    â”œâ”€â”€ run_phase1.py            # Phase 1 launcher
â”‚    â”œâ”€â”€ run_phase2.py            # (coming soon)
â”‚    â”œâ”€â”€ run_phase3.py            # (coming soon)
â”‚    â””â”€â”€ run_full.py              # (coming soon)
â”‚
â”‚â”€â”€ assets/
â”‚    â”œâ”€â”€ pipeline.png             # training pipeline illustration
â”‚    â”œâ”€â”€ modules.png              # model architecture illustration (optional)
â”‚
â”‚â”€â”€ models/                       # teacher & student encoders
â”‚â”€â”€ data/                         # dataset preprocessing
â”‚â”€â”€ utils/                        # dataloaders, configs, metrics
â”‚â”€â”€ ckpt/                         # checkpoints (auto-generated)
â”‚â”€â”€ README.md
```

---

## ðŸ“¢ Release Plan  

- âœ… **Phase 1**: Teacher pretraining (released now)  
- ðŸ”’ **Phase 2**: Multi-View Graph Collaborative Learning (to be released after acceptance)  
- ðŸ”’ **Phase 3**: Adaptive Sequential Distillation (to be released after acceptance)  

---


